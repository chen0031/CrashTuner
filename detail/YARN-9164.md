# YARN-9164

## Scenario

<div  align="center">    
 <img src="https://github.com/lujiefsi/CrashTuner/blob/master/pictures/9164.png" width="100%" height="100%" alt="YARN-9164" align=center />
</div>

1. A job finishes and YARN will clean the containers on each node.
2. YARN will get each node by NodeId.
3. If one node just crashes, recovery process removes it from cluster.
4. so no node is obtained, but yarn still use it, hence NPE happens.
5. Due to YARN can't handle such exception, it will exit directly.  

## Trigger analysis

```
 public N getNode(NodeId nodeId) {
   readLock.lock();
   try {
     return nodes.get(nodeId);
   } finally {
     readLock.unlock();
   }
 }
```

1. Above function code is the place where we read the nodes.
2. This function has about 43 different contexts.
3. About 25 contexts have sanity check, so **context sensitive** is so import to trigger this bug.
4. Above code also has lock, moving the crash point to caller can also help us **avoid lock**. 

## Crash Point
pre-read
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler completedContainer 687
